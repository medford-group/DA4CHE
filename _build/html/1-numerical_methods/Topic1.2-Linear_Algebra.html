
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Linear Algebra &#8212; Data Analytics for Chemical Engineers</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1-numerical_methods/Topic1.2-Linear_Algebra';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Linear Regression" href="Topic1.3-Linear_Regression.html" />
    <link rel="prev" title="Python Basics" href="Topic1.1-Python_Basics.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Data Analytics for Chemical Engineers</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Numerical Methods</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Topic1.1-Python_Basics.html">Python Basics</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Linear Algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="Topic1.3-Linear_Regression.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="Topic1.4-Numerical_Optimization.html">Numerical Optimization</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../2-regression/intro.html">Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../2-regression/Topic2.1-Non-parametric_Models.html">Non-parametric Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2-regression/Topic2.2-Model_Validation.html">Model Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2-regression/Topic2.3-Complexity_Optimization.html">Complexity Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2-regression/Topic2.4-High_Dimensional_Regression.html">High-dimensional Regression</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/1-numerical_methods/Topic1.2-Linear_Algebra.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Linear Algebra</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-vector-multiplication">Matrix-vector multiplication</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-matrix-vector-multiplication-with-nested-loops">Demonstration: Matrix-vector multiplication with nested loops</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-create-a-2nd-order-vandermonde-matrix">Demonstration: Create a 2nd-order Vandermonde matrix</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#norms-inner-products-and-orthogonality">Norms, inner products, and orthogonality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-create-an-orthonormal-version-of-the-vandermonde-matrix-gram-schmidt">Demonstration: Create an orthonormal version of the Vandermonde matrix (Gram-Schmidt)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-inverses-and-linear-systems">Rank, Inverses, and Linear Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-what-happens-if-we-add-redundant-rows">Demonstration: What happens if we add redundant rows?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eigen-and-singular-value-decompositions">Eigen and Singular Value Decompositions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-eigenvalues-and-condition-number">Rank, eigenvalues, and condition number</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-reading">Additional Reading</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <nav class="contents local" id="contents" role="doc-toc">
<ul class="simple">
<li><p><a class="reference internal" href="#linear-algebra" id="id1">Linear Algebra</a></p>
<ul>
<li><p><a class="reference internal" href="#learning-objectives" id="id2">Learning Objectives</a></p></li>
<li><p><a class="reference internal" href="#matrix-vector-multiplication" id="id3">Matrix-vector multiplication</a></p></li>
<li><p><a class="reference internal" href="#norms-inner-products-and-orthogonality" id="id4">Norms, inner products, and orthogonality</a></p></li>
<li><p><a class="reference internal" href="#rank-inverses-and-linear-systems" id="id5">Rank, Inverses, and Linear Systems</a></p></li>
<li><p><a class="reference internal" href="#eigen-and-singular-value-decompositions" id="id6">Eigen and Singular Value Decompositions</a></p></li>
<li><p><a class="reference internal" href="#additional-reading" id="id7">Additional Reading</a></p></li>
</ul>
</li>
</ul>
</nav>
<section class="tex2jax_ignore mathjax_ignore" id="linear-algebra">
<h1><a class="toc-backref" href="#id1" role="doc-backlink">Linear Algebra</a><a class="headerlink" href="#linear-algebra" title="Link to this heading">#</a></h1>
<p>Linear algebra is required for all engineers, but the conceptual aspects are often not taught or have been forgotten. This section provides a refresher on key computational and conceptual tools in matrix algebra and vector spaces.</p>
<section id="learning-objectives">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Learning Objectives</a><a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<p>By the end of this section, you should be able to:</p>
<ul class="simple">
<li><p>Construct and interpret matrix-vector products using polynomial basis sets</p></li>
<li><p>Compute vector norms and inner products; identify orthogonal relationships</p></li>
<li><p>Solve systems of equations using matrix factorizations and interpret matrix rank</p></li>
<li><p>Compare eigendecomposition and SVD; apply both to analyze matrix structure</p></li>
<li><p>Evaluate matrix conditioning using eigenvalues and singular values</p></li>
</ul>
</section>
<section id="matrix-vector-multiplication">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Matrix-vector multiplication</a><a class="headerlink" href="#matrix-vector-multiplication" title="Link to this heading">#</a></h2>
<p>First, some definitions:</p>
<ul class="simple">
<li><p>Dot product or “inner product”:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\vec{a} \cdot{} \vec{b} = \sum_i a_i b_i\)</span></p>
<ul class="simple">
<li><p>Matrix/vector multiplication:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\bar{\bar{A}} \vec{x} = \sum_j A_{ij} x_j = b_i\)</span></p>
<ul class="simple">
<li><p>Matrix/matrix multiplication:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\bar{\bar{A}} \bar{\bar{B}} = \sum_j A_{ij} B_{jk}\)</span></p>
<p>Note that we use “summation” or “index” notation in these definitions. It may look scary or difficult at first, but it can be very useful for programming. The sums turn into for loops, and the indices map directly from the notation into the code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># standard and recommended import convention</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;../settings/plot_style.mplstyle&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These standard import statements will appear at the beginning of most notes to set up the environment.</p>
</div>
<hr class="docutils" />
<section id="demonstration-matrix-vector-multiplication-with-nested-loops">
<h3>Demonstration: Matrix-vector multiplication with nested loops<a class="headerlink" href="#demonstration-matrix-vector-multiplication-with-nested-loops" title="Link to this heading">#</a></h3>
<p>This example uses Python <code class="docutils literal notranslate"><span class="pre">for</span></code> loops to multiply a <span class="math notranslate nohighlight">\(2\times2\)</span> matrix with a 2-element vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="nb">sum</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
3
</pre></div>
</div>
</div>
</div>
<p>This matches what we expect from manual matrix multiplication:</p>
<ul class="simple">
<li><p>First row: <span class="math notranslate nohighlight">\(0 \cdot 0 + 1 \cdot 1 = 1\)</span></p></li>
<li><p>Second row: <span class="math notranslate nohighlight">\(2 \cdot 0 + 3 \cdot 1 = 3\)</span></p></li>
</ul>
<hr class="docutils" />
<p>We will explore matrix-vector multiplication conceptually by constructing a dataset from the “Vandermonde” matrix of polynomials and a weight vector, <span class="math notranslate nohighlight">\(\vec{w}\)</span> to construct a dataset of the form:</p>
<p><span class="math notranslate nohighlight">\(y_i = w_0 + w_1 x_i + w_2 x_i^2\)</span></p>
<p>It may be useful to write this in summation notation and compare it to the matrix-vector multiplication definition:</p>
<p><span class="math notranslate nohighlight">\(y_i = \sum_{j=0}^2 w_j x_i^{\: j}\)</span></p>
<p>First, we can use <code class="docutils literal notranslate"><span class="pre">numpy</span></code> to create a vector <span class="math notranslate nohighlight">\(x_i\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
<span class="n">xi</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
</pre></div>
</div>
</div>
</div>
<p>Now, we can create a new vector <span class="math notranslate nohighlight">\(z_i = x_i^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zi</span> <span class="o">=</span> <span class="n">xi</span><span class="o">**</span><span class="mi">2</span>
<span class="n">zi</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([  0.,   1.,   4.,   9.,  16.,  25.,  36.,  49.,  64.,  81., 100.])
</pre></div>
</div>
</div>
</div>
<p>Next, let’s create a vector that contains each of the weight parameters, <span class="math notranslate nohighlight">\(w_j\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wj</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can now construct <span class="math notranslate nohighlight">\(y_i\)</span> manually:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yi</span> <span class="o">=</span> <span class="n">wj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">wj</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">xi</span> <span class="o">+</span> <span class="n">wj</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">zi</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x_i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y_i$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/15d0dc6bd9155a04ef5a6665b619bb5cbd29b04ca99ef48ae1227a15a75fe24d.png" src="../_images/15d0dc6bd9155a04ef5a6665b619bb5cbd29b04ca99ef48ae1227a15a75fe24d.png" />
</div>
</div>
<hr class="docutils" />
<p>This works, but we can create the same dataset using a <strong>Vandermonde matrix</strong>, which is a matrix of polynomials defined as:</p>
<p><span class="math notranslate nohighlight">\(X_{ij} = x_i^{\: j}\)</span></p>
<p>In other words, each column of the matrix consists of a different polynomial.</p>
<p>We can construct this matrix using <code class="docutils literal notranslate"><span class="pre">numpy</span></code>. First, we need to turn <span class="math notranslate nohighlight">\(x_i\)</span> into a column vector:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_i vector shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xi</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">xi_col</span> <span class="o">=</span> <span class="n">xi</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># equivalent to xi.reshape((xi.shape[0], 1))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_i column shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xi_col</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x_i vector shape: (11,)
x_i column shape: (11, 1)
</pre></div>
</div>
</div>
</div>
<p>Now, we can “stack” these vectors together to create the Vandermonde matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xi</span> <span class="o">=</span> <span class="n">xi_col</span>
<span class="n">X_vdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">xi</span><span class="o">**</span><span class="mi">0</span><span class="p">,</span> <span class="n">xi</span><span class="o">**</span><span class="mi">1</span><span class="p">,</span> <span class="n">xi</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">X_vdm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[  1.,   0.,   0.],
       [  1.,   1.,   1.],
       [  1.,   2.,   4.],
       [  1.,   3.,   9.],
       [  1.,   4.,  16.],
       [  1.,   5.,  25.],
       [  1.,   6.,  36.],
       [  1.,   7.,  49.],
       [  1.,   8.,  64.],
       [  1.,   9.,  81.],
       [  1.,  10., 100.]])
</pre></div>
</div>
</div>
</div>
<p>Next we can directly create <span class="math notranslate nohighlight">\(y_i\)</span> using matrix-vector multiplication based on the definition of matrix-vector multiplication:</p>
<p><span class="math notranslate nohighlight">\(\bar{\bar{X}}\vec{w} = \sum_j X_{ij}w_j = w_0 + w_1 x_i + w_2 x_i^2\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yi_vdm</span> <span class="o">=</span> <span class="n">X_vdm</span> <span class="o">@</span> <span class="n">wj</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi_vdm</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/218690c84f3f8c58fd06933d813b0ae961567203c936473ab64cfacfecb64474.png" src="../_images/218690c84f3f8c58fd06933d813b0ae961567203c936473ab64cfacfecb64474.png" />
</div>
</div>
<p>We can verify that both approaches yield the same <span class="math notranslate nohighlight">\(y_i\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yi</span> <span class="o">==</span> <span class="n">yi_vdm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True, False,  True, False, False,  True,  True,
       False, False])
</pre></div>
</div>
</div>
</div>
<p>Since numerical methods often introduce small round-off error, it’s better to use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">yi</span><span class="p">,</span> <span class="n">yi_vdm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True])
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.all()</span></code> method is commonly used with <code class="docutils literal notranslate"><span class="pre">np.isclose()</span></code> to check if <em>all</em> elements of an array are <code class="docutils literal notranslate"><span class="pre">True</span></code>. This is useful when confirming whether two arrays are element-wise equal to within a small tolerance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">yi</span><span class="p">,</span> <span class="n">yi_vdm</span><span class="p">)</span>
<span class="n">M</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>  <span class="c1"># True if every element in M is True</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="demonstration-create-a-2nd-order-vandermonde-matrix">
<h3>Demonstration: Create a 2nd-order Vandermonde matrix<a class="headerlink" href="#demonstration-create-a-2nd-order-vandermonde-matrix" title="Link to this heading">#</a></h3>
<p>This example shows how to build a Vandermonde matrix using <code class="docutils literal notranslate"><span class="pre">hstack</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1">#a slightly fancy one-liner to make a column vector</span>
<span class="n">vdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x</span><span class="o">**</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">vdm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.  0.  0.]
 [ 1.  1.  1.]
 [ 1.  2.  4.]
 [ 1.  3.  9.]
 [ 1.  4. 16.]
 [ 1.  5. 25.]]
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Write a function <code class="docutils literal notranslate"><span class="pre">matmul_loops(A,</span> <span class="pre">B)</span></code> that multiplies two matrices using nested <code class="docutils literal notranslate"><span class="pre">for</span></code> loops. Then compare the result with the built-in matrix multiplication using <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code>.</p>
<p>Use the following test input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Verify that both results are the same (use <code class="docutils literal notranslate"><span class="pre">np.allclose</span></code>)</p></li>
<li><p>Print the result of your function and the built-in multiplication</p></li>
</ul>
</div>
</section>
</section>
<section id="norms-inner-products-and-orthogonality">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Norms, inner products, and orthogonality</a><a class="headerlink" href="#norms-inner-products-and-orthogonality" title="Link to this heading">#</a></h2>
<p>Vectors can be described by various “norms” that capture their size and distance. The most common is the <span class="math notranslate nohighlight">\(L_2\)</span> norm, also called the <strong>Euclidean norm</strong>, defined as:</p>
<div class="math notranslate nohighlight">
\[
||\vec{x}||_2 = \sqrt{\sum_i x_i^2}
\]</div>
<p>This can also be computed using the inner product of a vector with itself:</p>
<div class="math notranslate nohighlight">
\[
||\vec{x}||_2 = \sqrt{\vec{x}^T \vec{x}}
\]</div>
<p>A vector is called “normal” if its norm is 1. We can always <strong>normalize</strong> a vector by dividing it by its norm:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_0</span> <span class="o">=</span> <span class="n">X_vdm</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">norm_col_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">col_0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">col_0_normed</span> <span class="o">=</span> <span class="n">col_0</span><span class="o">/</span><span class="n">norm_col_0</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Column norm: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">norm_col_0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Normed column norm: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">col_0_normed</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Column norm: 3.3166247903554
Normed column norm: 1.0
</pre></div>
</div>
</div>
</div>
<p>We will also occasionally use the <span class="math notranslate nohighlight">\(L_1\)</span> norm, defined as:</p>
<div class="math notranslate nohighlight">
\[
||\vec{x}||_1 = \sum_i |x_i|
\]</div>
<p>These norms, and others, are discussed in detail in <a class="reference external" href="https://github.com/jermwatt/machine_learning_refined/blob/gh-pages/notes/16_Linear_algebra/16_5_Norms.ipynb">Machine Learning Refined</a> and Lecture 3 of Trefethen &amp; Bau.</p>
<hr class="docutils" />
<p>It is also useful to remember that the inner product between two different vectors equals the product of their magnitudes and the cosine of the angle between them:</p>
<div class="math notranslate nohighlight">
\[
\vec{x}^T\vec{y} = ||\vec{x}||_2 ||\vec{y}||_2 \cos(\theta)
\]</div>
<p>This allows us to compute the angle between two <strong>normalized</strong> vectors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_1</span> <span class="o">=</span> <span class="n">X_vdm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">norm_col_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">col_1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">col_1_normed</span> <span class="o">=</span> <span class="n">col_1</span><span class="o">/</span><span class="n">norm_col_1</span>

<span class="n">cos_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col_1_normed</span><span class="p">,</span> <span class="n">col_0_normed</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">degrees</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">cos_theta</span><span class="p">))</span>
<span class="n">theta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(32.31153323742384)
</pre></div>
</div>
</div>
</div>
<p>Vectors are defined as <strong>orthogonal</strong> if their inner product is zero. We can check this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">degrees</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">theta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(90.0)
</pre></div>
</div>
</div>
</div>
<p>This shows that orthogonal vectors are separated by 90 degrees — or have no projection onto each other.</p>
<hr class="docutils" />
<p>One key concept that comes in handy is the ability to find the orthogonal components of an arbitrary set of vectors. We can do this by subtracting off the projection of one vector onto another:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">col_1_ortho</span> <span class="o">=</span> <span class="n">col_1_normed</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col_0_normed</span><span class="p">,</span> <span class="n">col_1_normed</span><span class="p">)</span><span class="o">*</span><span class="n">col_0_normed</span>
<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col_1_ortho</span><span class="p">,</span> <span class="n">col_0_normed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(-1.1102230246251565e-16)
</pre></div>
</div>
</div>
</div>
<p>While this isn’t exactly zero, it is very close:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">col_1_ortho</span><span class="p">,</span> <span class="n">col_0_normed</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.True_
</pre></div>
</div>
</div>
</div>
<p>There is a discussion and proof of why this works in Lecture 2 of Trefethen &amp; Bau.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These vectors don’t appear to be at “right angles” in the plot — and that’s okay!<br />
Remember that they live in <strong>11-dimensional space</strong>, so our visual intuition does not apply directly.</p>
</div>
<p>Let’s compare the original normalized vectors and their orthogonal counterparts:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">col_0_normed</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">col_1_normed</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">col_0_normed</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">col_1_ortho</span><span class="p">,</span> <span class="s1">&#39;--o&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/db676e97c6c2b9947410daff8518e3d55369dee1c9a8da9927fe381020ead97b.png" src="../_images/db676e97c6c2b9947410daff8518e3d55369dee1c9a8da9927fe381020ead97b.png" />
</div>
</div>
<hr class="docutils" />
<section id="demonstration-create-an-orthonormal-version-of-the-vandermonde-matrix-gram-schmidt">
<h3>Demonstration: Create an orthonormal version of the Vandermonde matrix (Gram-Schmidt)<a class="headerlink" href="#demonstration-create-an-orthonormal-version-of-the-vandermonde-matrix-gram-schmidt" title="Link to this heading">#</a></h3>
<p>We can perform Gram-Schmidt orthonormalization on the first two columns of the Vandermonde matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">vdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">**</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">**</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Orthonormalizing the 1st column</span>
<span class="n">ortho_1</span> <span class="o">=</span> <span class="n">vdm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vdm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Orthonormalizing the 2nd column relative to the 1st</span>
<span class="n">proj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ortho_1</span><span class="p">,</span> <span class="n">vdm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">ortho_1</span>
<span class="n">ortho_2</span> <span class="o">=</span> <span class="n">vdm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">proj</span>
<span class="n">ortho_2</span> <span class="o">=</span> <span class="n">ortho_2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">ortho_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ortho_1</span><span class="p">,</span> <span class="n">ortho_2</span><span class="p">))</span>  <span class="c1"># should be ~0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-5.273559366969494e-16
</pre></div>
</div>
</div>
</div>
<p>This confirms that the two orthonormal vectors are perpendicular.</p>
<hr class="docutils" />
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Use a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop to perform Gram-Schmidt orthonormalization on the first <strong>three columns</strong> of a Vandermonde matrix.</p>
<p>Start with this matrix:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">vdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x</span><span class="o">**</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>Your loop should:</p>
<ul class="simple">
<li><p>Normalize the first column</p></li>
<li><p>Subtract off the projection of each subsequent column onto all previously normalized vectors</p></li>
<li><p>Normalize the result at each step</p></li>
</ul>
<p>Use <code class="docutils literal notranslate"><span class="pre">np.dot()</span></code> and <code class="docutils literal notranslate"><span class="pre">np.linalg.norm()</span></code> as needed. Check that the resulting vectors are orthogonal by computing their pairwise dot products.</p>
</div>
</section>
</section>
<section id="rank-inverses-and-linear-systems">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Rank, Inverses, and Linear Systems</a><a class="headerlink" href="#rank-inverses-and-linear-systems" title="Link to this heading">#</a></h2>
<p>Before we dive into rank and matrix inverses, it’s helpful to recall the connection between <strong>systems of equations</strong> and <strong>matrix-vector notation</strong>.</p>
<p>Consider this system of equations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
2x + y &amp;= 5 \\
3x - y &amp;= 4
\end{align*}
\end{split}\]</div>
<p>We can rewrite this in matrix-vector form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
2 &amp; 1 \\
3 &amp; -1
\end{bmatrix}
\begin{bmatrix}
x \\
y
\end{bmatrix}
=
\begin{bmatrix}
5 \\
4
\end{bmatrix}
\end{split}\]</div>
<p>Or more compactly as:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}} \vec{x} = \vec{b}
\]</div>
<p>This form lets us use tools from linear algebra to solve the system, analyze its properties, or even approximate solutions when exact ones don’t exist.</p>
<hr class="docutils" />
<p>The concept of the <strong>rank</strong> of a matrix is fundamental. Formally, the rank is the number of <strong>linearly independent columns or rows</strong>.</p>
<p>For an <span class="math notranslate nohighlight">\(m \times n\)</span> matrix, the rank is always less than or equal to the minimum of <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(n\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\text{rank} \leq \min(m, n)
\]</div>
<hr class="docutils" />
<p>It’s helpful to connect this with the matrix-vector equation:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}}\vec{x} = \vec{b}
\]</div>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(m = n\)</span> and <span class="math notranslate nohighlight">\(\bar{\bar{A}}\)</span> has <strong>full rank</strong>, the system has a <strong>unique solution</strong>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(m &gt; n\)</span>, the system is <strong>overconstrained</strong> — there are more equations than unknowns.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(m &lt; n\)</span>, the system is <strong>underdetermined</strong> — more unknowns than equations.</p></li>
</ul>
<p>A matrix is <strong>invertible</strong> if and only if it is <strong>square and full-rank</strong>. That means all rows (and columns) are linearly independent.</p>
<hr class="docutils" />
<p>Let’s look at a concrete example using the Vandermonde matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">X_vdm</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">yi</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of A: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rank of A: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>

<span class="n">A_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">A_inv</span> <span class="o">@</span> <span class="n">b</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weights: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of A: (3, 3)
Rank of A: 3
Weights: [ 1.5  0.8 -0.2]
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<section id="demonstration-what-happens-if-we-add-redundant-rows">
<h3>Demonstration: What happens if we add redundant rows?<a class="headerlink" href="#demonstration-what-happens-if-we-add-redundant-rows" title="Link to this heading">#</a></h3>
<p>Let’s check how the rank changes when we add a redundant equation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>  <span class="c1"># should be 2</span>

<span class="c1"># Add a third, redundant row</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>  <span class="c1"># still 2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
2
</pre></div>
</div>
</div>
</div>
<p>The third row does not provide new information, so the rank remains 2.</p>
<hr class="docutils" />
<p>In practice, solving systems of equations using matrix inverses (<code class="docutils literal notranslate"><span class="pre">np.linalg.inv</span></code>) is inefficient and numerically unstable. Instead, we use built-in solvers like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_solve</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">w_solve</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.True_
</pre></div>
</div>
</div>
</div>
<p>This is the preferred approach in both practice and in this course. It only works when:</p>
<ol class="arabic simple">
<li><p>You can write the system as <span class="math notranslate nohighlight">\(\bar{\bar{A}}\vec{x} = \vec{b}\)</span></p></li>
<li><p>The matrix <span class="math notranslate nohighlight">\(\bar{\bar{A}}\)</span> is square and full-rank</p></li>
</ol>
<hr class="docutils" />
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Given the matrix:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">np.linalg.matrix_rank(A)</span></code> to determine whether the matrix is full rank.</p></li>
<li><p>Try solving the system using <code class="docutils literal notranslate"><span class="pre">np.linalg.solve(A,</span> <span class="pre">b)</span></code> — what happens?</p></li>
<li><p>Now modify <code class="docutils literal notranslate"><span class="pre">A</span></code> so that it becomes full rank. Solve the system again.</p></li>
</ol>
<p>This exercise will help you build intuition for how rank affects solvability.</p>
</div>
</section>
</section>
<section id="eigen-and-singular-value-decompositions">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Eigen and Singular Value Decompositions</a><a class="headerlink" href="#eigen-and-singular-value-decompositions" title="Link to this heading">#</a></h2>
<p>One powerful tool in linear algebra is the <strong>eigenvalue decomposition</strong>, or eigendecomposition, which expresses a square matrix in terms of its eigenvalues and eigenvectors.</p>
<p>For a matrix <span class="math notranslate nohighlight">\(\bar{\bar{A}}\)</span>, an eigenvalue problem looks like:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}} \vec{v}_n = \lambda_n \vec{v}_n
\]</div>
<p>where <span class="math notranslate nohighlight">\(\vec{v}_n\)</span> is an <strong>eigenvector</strong>, and <span class="math notranslate nohighlight">\(\lambda_n\)</span> is the corresponding <strong>eigenvalue</strong>.</p>
<p>This means that when <span class="math notranslate nohighlight">\(\bar{\bar{A}}\)</span> acts on <span class="math notranslate nohighlight">\(\vec{v}_n\)</span>, the result is just a scaled version of <span class="math notranslate nohighlight">\(\vec{v}_n\)</span> — not rotated or altered in direction.</p>
<p>To compute eigenvalues in Python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">numpy.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">eigvals</span><span class="p">,</span> <span class="n">eig</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Eigenvalues of A: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">eigvals</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvalues of A: [10.60311024  1.24543789  0.15145187]
</pre></div>
</div>
</div>
</div>
<p>To get both eigenvalues and eigenvectors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vals</span><span class="p">,</span> <span class="n">vecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Eigenvectors of A: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vecs</span><span class="p">))</span>

<span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">eigvals</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>  <span class="c1"># should be True</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvectors of A: [[-0.13772903 -0.81480675  0.65820453]
 [-0.43070617 -0.49754289 -0.7324674 ]
 [-0.89192091  0.29755844  0.17394918]]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True])
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a matrix is <strong>not symmetric</strong>, its eigenvalues and eigenvectors may be <strong>complex</strong>.<br />
In this context, “complex” means they may include <strong>imaginary numbers</strong>, such as <span class="math notranslate nohighlight">\(1 + 2i\)</span>.</p>
<p>This is not a numerical error — it reflects the fact that real, non-symmetric transformations can involve rotation and scaling in ways that cannot be captured by real numbers alone.</p>
<p>Symmetric matrices always have <strong>real</strong> eigenvalues and orthogonal eigenvectors, which is one reason they’re so widely used.</p>
</div>
<hr class="docutils" />
<p>If the matrix is <strong>symmetric</strong>, then the eigenvectors will always be <strong>orthonormal</strong>. Let’s construct a symmetric matrix and check:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A_sym</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">A</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span>  <span class="c1"># make A symmetric</span>
<span class="n">vals</span><span class="p">,</span> <span class="n">vecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">A_sym</span><span class="p">)</span>

<span class="n">vec0</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">vec1</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">vec2</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">vec0</span> <span class="o">@</span> <span class="n">vec1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.True_
</pre></div>
</div>
</div>
</div>
<p>This confirms that the eigenvectors are orthogonal.</p>
<hr class="docutils" />
<p>Eigendecomposition only works for square matrices, but there is a more general tool called <strong>singular value decomposition</strong>, or SVD, which applies to <strong>any</strong> matrix:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}} = \hat{U} \hat{\Sigma} \hat{V}^T
\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{U}\)</span> contains the <strong>left singular vectors</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{V}\)</span> contains the <strong>right singular vectors</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> is a diagonal matrix of <strong>singular values</strong></p></li>
</ul>
<p>The <strong>singular value decomposition (SVD)</strong> is closely related to eigendecomposition — in fact, for a square <strong>symmetric</strong> matrix:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}} = \hat{U} \hat{\Sigma} \hat{U}^T
\]</div>
<p>This is mathematically equivalent to the eigendecomposition:</p>
<div class="math notranslate nohighlight">
\[
\bar{\bar{A}} = \bar{\bar{V}} \bar{\bar{\Lambda}} \bar{\bar{V}}^T
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">numpy.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">svd</span>

<span class="n">vecsL</span><span class="p">,</span> <span class="n">vals</span><span class="p">,</span> <span class="n">vecsR</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">A_sym</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">vecsR</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:],</span> <span class="n">vecs</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># should be close</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True])
</pre></div>
</div>
</div>
</div>
<p>Even when the matrix is not square, the SVD still works:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vecsL</span><span class="p">,</span> <span class="n">vals</span><span class="p">,</span> <span class="n">vecsR</span> <span class="o">=</span> <span class="n">svd</span><span class="p">(</span><span class="n">X_vdm</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Original matrix shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_vdm</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Left singular vectors shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vecsL</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Right singular vectors shape: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vecsR</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Singular Values: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vals</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original matrix shape: (11, 3)
Left singular vectors shape: (11, 11)
Right singular vectors shape: (3, 3)
Singular Values: [160.3135455    5.20337928   1.22146387]
</pre></div>
</div>
</div>
</div>
<p>The number of singular values equals the rank of the matrix, and they provide useful information about the structure of the data.</p>
<p>Here’s what distinguishes the SVD from the eigendecomposition:</p>
<ul class="simple">
<li><p><strong>Eigendecomposition</strong> only applies to <strong>square</strong> matrices.</p></li>
<li><p><strong>SVD</strong> applies to <strong>any</strong> matrix, even rectangular ones.</p></li>
<li><p>The eigenvalues of <span class="math notranslate nohighlight">\(\bar{\bar{A}}^T \bar{\bar{A}}\)</span> (or <span class="math notranslate nohighlight">\(\bar{\bar{A}} \bar{\bar{A}}^T\)</span>) correspond to the <strong>squares</strong> of the singular values in the SVD.</p></li>
<li><p>SVD always yields <strong>real, non-negative singular values</strong>, even for non-symmetric matrices.</p></li>
</ul>
<p>In short: <strong>SVD is more general</strong>, and often more numerically stable, but conceptually similar. Many machine learning algorithms rely on it under the hood.</p>
<p>For more details, see Lecture 4 of Trefethen &amp; Bau.</p>
<hr class="docutils" />
<section id="rank-eigenvalues-and-condition-number">
<h3>Rank, eigenvalues, and condition number<a class="headerlink" href="#rank-eigenvalues-and-condition-number" title="Link to this heading">#</a></h3>
<p>We’ve seen how the <strong>rank</strong> of a matrix determines whether a system can be solved uniquely. But what if the matrix is <strong>almost</strong> rank-deficient?</p>
<p>That is, the matrix is full-rank numerically, but one of its singular values is very close to zero. In these cases, the matrix is <strong>ill-conditioned</strong>, and small changes in input can produce large errors in the result.</p>
<p>We can detect this using the <strong>condition number</strong>:</p>
<div class="math notranslate nohighlight">
\[
\text{cond}(\bar{\bar{A}}) = \frac{\sigma_{\max}}{\sigma_{\min}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma_{\max}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{\min}\)</span> are the largest and smallest singular values, respectively.</p>
<p>A large condition number indicates an unstable system. A condition number of <span class="math notranslate nohighlight">\(10^3\)</span> is mildly ill-conditioned; <span class="math notranslate nohighlight">\(10^8\)</span> or higher is seriously problematic.</p>
<p>Let’s compute it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">numpy.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">cond</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.00001</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Condition number: </span><span class="si">{:.2e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cond</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Condition number: 4.00e+05
</pre></div>
</div>
</div>
</div>
<p>This matrix is nearly singular — it has two nearly linearly dependent rows (i.e. if 1.00001 was rounded to 1, the two rows would be exactly the same). Let’s see what happens when we try to invert it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[100000.99999934, -99999.99999934],
       [-99999.99999934,  99999.99999934]])
</pre></div>
</div>
</div>
</div>
<p>You may get an answer, but it is likely to be numerically unreliable.</p>
<div class="tip admonition">
<p class="admonition-title">Exercise</p>
<p>Let</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mf">10.00001</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</pre></div>
</div>
<ol class="arabic simple">
<li><p>Compute the eigenvalues using <code class="docutils literal notranslate"><span class="pre">np.linalg.eigvals</span></code>.</p></li>
<li><p>Based on their values, what is the rank of <code class="docutils literal notranslate"><span class="pre">A</span></code>?</p></li>
<li><p>Estimate the condition number by dividing the larger eigenvalue by the smaller one.</p></li>
<li><p>Now repeat with:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mf">10.00001</span><span class="p">]])</span>
</pre></div>
</div>
<p>What changes? What does this tell you about the numerical stability of solving <span class="math notranslate nohighlight">\(\bar{\bar{A}}\vec{x} = \vec{b}\)</span>?</p>
<p>Note: For symmetric matrices, the ratio of eigenvalues approximates the condition number.</p>
</div>
</section>
</section>
<section id="additional-reading">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Additional Reading</a><a class="headerlink" href="#additional-reading" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Trefethen &amp; Bau, <em>Numerical Linear Algebra</em> (Lectures 2–4)</p></li>
<li><p><a class="reference external" href="https://github.com/jermwatt/machine_learning_refined/blob/gh-pages/notes/16_Linear_algebra">Machine Learning Refined: Linear Algebra</a></p></li>
<li><p><a class="reference external" href="https://cs229.stanford.edu/section/cs229-linalg.pdf">CS229 Notes: Linear Algebra Review</a></p></li>
<li><p>Strang, <em>Introduction to Linear Algebra</em></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./1-numerical_methods"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Topic1.1-Python_Basics.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Python Basics</p>
      </div>
    </a>
    <a class="right-next"
       href="Topic1.3-Linear_Regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Linear Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-vector-multiplication">Matrix-vector multiplication</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-matrix-vector-multiplication-with-nested-loops">Demonstration: Matrix-vector multiplication with nested loops</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-create-a-2nd-order-vandermonde-matrix">Demonstration: Create a 2nd-order Vandermonde matrix</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#norms-inner-products-and-orthogonality">Norms, inner products, and orthogonality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-create-an-orthonormal-version-of-the-vandermonde-matrix-gram-schmidt">Demonstration: Create an orthonormal version of the Vandermonde matrix (Gram-Schmidt)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-inverses-and-linear-systems">Rank, Inverses, and Linear Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-what-happens-if-we-add-redundant-rows">Demonstration: What happens if we add redundant rows?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eigen-and-singular-value-decompositions">Eigen and Singular Value Decompositions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-eigenvalues-and-condition-number">Rank, eigenvalues, and condition number</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-reading">Additional Reading</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By A.J. Medford
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  © 2025 A.J. Medford
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>